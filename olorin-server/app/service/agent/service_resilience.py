"""
Service Integration Resilience System

External service failure detection, LLM API fallback strategies, database connectivity
resilience, and WebSocket communication resilience for the structured investigation
orchestrator system.

Phase 3.2: Service Integration Resilience Implementation
"""

import asyncio
import json
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Callable, Union, Set
from dataclasses import dataclass, field
from enum import Enum
import aiohttp
import hashlib
from collections import defaultdict, deque
import redis.asyncio as redis

from app.service.logging import get_bridge_logger
from app.service.agent.orchestrator_resilience import (
    CircuitBreakerState,
    CircuitBreaker,
    get_bulletproof_exception_handler
)

logger = get_bridge_logger(__name__)


class ServiceType(Enum):
    """Types of external services"""
    LLM_API = "llm_api"          # OpenAI, Anthropic APIs
    DATABASE = "database"        # Primary database connection
    CACHE = "cache"             # Redis cache
    THREAT_INTEL = "threat_intel" # Threat intelligence APIs
    SPLUNK = "splunk"           # SIEM integration
    WEBSOCKET = "websocket"     # Real-time communication
    EXTERNAL_API = "external_api" # General external APIs


class FailureDetectionMode(Enum):
    """Service failure detection modes"""
    REACTIVE = "reactive"        # Detect failures on error
    PROACTIVE = "proactive"      # Health check monitoring
    PREDICTIVE = "predictive"    # ML-based prediction
    HYBRID = "hybrid"           # Combined approach


class CacheStrategy(Enum):
    """Data caching strategies for resilience"""
    NO_CACHE = "no_cache"
    SHORT_TERM = "short_term"    # Minutes
    MEDIUM_TERM = "medium_term"  # Hours
    LONG_TERM = "long_term"      # Days
    PERSISTENT = "persistent"    # Until invalidated


@dataclass
class ServiceHealth:
    """Service health status and metrics"""
    service_name: str
    service_type: ServiceType
    is_healthy: bool
    last_check: datetime
    response_time_ms: float
    error_rate: float
    success_count: int
    failure_count: int
    consecutive_failures: int
    health_score: float  # 0.0 to 1.0
    degradation_level: float  # 0.0 to 1.0
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class FallbackStrategy:
    """Fallback strategy configuration"""
    strategy_id: str
    service_type: ServiceType
    priority: int  # Lower number = higher priority
    handler: Callable
    prerequisites: List[str]
    success_rate: float
    avg_latency_ms: float
    resource_cost: float  # Relative cost factor
    description: str


@dataclass
class CachedData:
    """Cached data with metadata"""
    cache_key: str
    data: Any
    timestamp: datetime
    expiry: datetime
    cache_strategy: CacheStrategy
    hit_count: int = 0
    quality_score: float = 1.0  # Data quality/freshness
    metadata: Dict[str, Any] = field(default_factory=dict)


class ServiceResilienceManager:
    """
    Service Integration Resilience Manager for external service failures.
    
    Provides comprehensive failure detection, fallback strategies, intelligent caching,
    and resilient communication patterns for all external service dependencies.
    """
    
    def __init__(self):
        self.service_health: Dict[str, ServiceHealth] = {}
        self.fallback_strategies: Dict[ServiceType, List[FallbackStrategy]] = {}
        self.cached_data: Dict[str, CachedData] = {}
        self.circuit_breakers: Dict[str, CircuitBreaker] = {}
        
        # Health monitoring
        self.health_check_tasks: Dict[str, asyncio.Task] = {}
        self.failure_patterns: Dict[str, deque] = defaultdict(lambda: deque(maxlen=100))
        
        # WebSocket resilience
        self.websocket_queue: deque = deque(maxlen=1000)
        self.websocket_retry_count: Dict[str, int] = defaultdict(int)
        
        # Initialize components
        self._initialize_service_health()
        self._initialize_fallback_strategies()
        self._initialize_circuit_breakers()
        
    async def detect_service_failures(
        self,
        service_name: str,
        detection_mode: FailureDetectionMode = FailureDetectionMode.HYBRID
    ) -> ServiceHealth:
        """
        Detect and assess service failures with comprehensive monitoring.
        
        Args:
            service_name: Name of the service to monitor
            detection_mode: Mode of failure detection
            
        Returns:
            Current service health status
        """
        logger.info(f"ðŸ” Detecting service failures for {service_name} using {detection_mode.value} mode")
        
        try:
            # Get or create service health record
            health = self.service_health.get(service_name)
            if not health:
                health = await self._initialize_service_health_record(service_name)
            
            # Apply detection mode
            if detection_mode in [FailureDetectionMode.PROACTIVE, FailureDetectionMode.HYBRID]:
                health = await self._proactive_health_check(service_name, health)
            
            if detection_mode in [FailureDetectionMode.PREDICTIVE, FailureDetectionMode.HYBRID]:
                health = await self._predictive_failure_analysis(service_name, health)
            
            # Update failure patterns
            await self._update_failure_patterns(service_name, health)
            
            # Determine overall health score
            health.health_score = await self._calculate_health_score(health)
            
            # Update degradation level
            health.degradation_level = await self._calculate_degradation_level(health)
            
            # Store updated health
            self.service_health[service_name] = health
            
            # Trigger circuit breaker if needed
            if health.consecutive_failures >= 3 and health.is_healthy:
                await self._trigger_circuit_breaker(service_name, health)
            
            logger.info(f"âœ… Service {service_name} health: {health.health_score:.2f} (degradation: {health.degradation_level:.2f})")
            return health
            
        except Exception as e:
            logger.error(f"ðŸš¨ Failed to detect service failures for {service_name}: {str(e)}")
            return await self._create_emergency_health_record(service_name)
    
    async def handle_llm_api_failures(
        self,
        investigation_id: str,
        primary_llm: str,
        prompt: str,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Handle LLM API failures with intelligent fallback strategies.
        
        Args:
            investigation_id: Investigation identifier
            primary_llm: Primary LLM service that failed
            prompt: Original prompt for LLM
            context: Request context and parameters
            
        Returns:
            LLM response from fallback strategy or rule-based alternative
        """
        logger.info(f"ðŸ¤– Handling LLM API failure for {primary_llm} in investigation {investigation_id}")
        
        try:
            # Get available fallback strategies for LLM APIs
            fallback_strategies = self.fallback_strategies.get(ServiceType.LLM_API, [])
            fallback_strategies.sort(key=lambda x: x.priority)
            
            # Attempt each fallback strategy
            for strategy in fallback_strategies:
                try:
                    # Check if strategy prerequisites are met
                    if await self._check_strategy_prerequisites(strategy, context):
                        logger.info(f"ðŸ”„ Attempting fallback strategy: {strategy.description}")
                        
                        # Execute fallback strategy
                        result = await strategy.handler(investigation_id, prompt, context)
                        
                        if result and result.get("success", False):
                            # Record successful fallback
                            await self._record_fallback_success(strategy, investigation_id)
                            
                            logger.info(f"âœ… LLM fallback successful with {strategy.strategy_id}")
                            return {
                                "success": True,
                                "response": result["response"],
                                "fallback_strategy": strategy.strategy_id,
                                "confidence_score": result.get("confidence_score", 0.7),
                                "processing_time": result.get("processing_time", 0),
                                "metadata": {
                                    "primary_llm_failed": primary_llm,
                                    "fallback_used": strategy.description
                                }
                            }
                
                except Exception as fallback_error:
                    logger.warning(f"âš ï¸ Fallback strategy {strategy.strategy_id} failed: {str(fallback_error)}")
                    continue
            
            # All fallback strategies failed, use rule-based response
            return await self._generate_rule_based_llm_response(investigation_id, prompt, context)
            
        except Exception as e:
            logger.error(f"ðŸš¨ Failed to handle LLM API failure: {str(e)}")
            return await self._create_emergency_llm_response(investigation_id, prompt)
    
    async def manage_database_connectivity(
        self,
        investigation_id: str,
        operation: str,
        data: Dict[str, Any],
        use_cache: bool = True
    ) -> Dict[str, Any]:
        """
        Manage database connectivity issues with caching and fallback strategies.
        
        Args:
            investigation_id: Investigation identifier
            operation: Database operation type
            data: Operation data
            use_cache: Whether to use cached data as fallback
            
        Returns:
            Database operation result or cached alternative
        """
        logger.info(f"ðŸ’¾ Managing database connectivity for operation {operation}")
        
        try:
            # Check database health
            db_health = await self.detect_service_failures("database", FailureDetectionMode.PROACTIVE)
            
            # If database is healthy, proceed normally
            if db_health.is_healthy and db_health.health_score > 0.8:
                result = await self._execute_database_operation(operation, data)
                
                # Cache successful results if appropriate
                if use_cache and operation.startswith("read"):
                    await self._cache_database_result(investigation_id, operation, result)
                
                return result
            
            # Database is degraded or unhealthy, use resilience strategies
            return await self._handle_database_degradation(
                investigation_id, operation, data, db_health, use_cache
            )
            
        except Exception as e:
            logger.error(f"ðŸš¨ Database connectivity management failed: {str(e)}")
            
            # Emergency fallback to cached data
            if use_cache:
                cached_result = await self._get_cached_database_result(investigation_id, operation)
                if cached_result:
                    return cached_result
            
            return await self._create_database_emergency_response(investigation_id, operation)
    
    async def ensure_websocket_resilience(
        self,
        investigation_id: str,
        message: Dict[str, Any],
        priority: str = "normal"
    ) -> bool:
        """
        Ensure WebSocket communication resilience with queuing and retry logic.
        
        Args:
            investigation_id: Investigation identifier
            message: WebSocket message to send
            priority: Message priority level
            
        Returns:
            Success status of message delivery
        """
        logger.info(f"ðŸ“¡ Ensuring WebSocket resilience for investigation {investigation_id}")
        
        try:
            # Check WebSocket service health
            ws_health = await self.detect_service_failures("websocket", FailureDetectionMode.REACTIVE)
            
            # Enhance message with resilience metadata
            enhanced_message = {
                **message,
                "investigation_id": investigation_id,
                "timestamp": datetime.now().isoformat(),
                "priority": priority,
                "retry_count": 0,
                "max_retries": 3 if priority == "high" else 1
            }
            
            # If WebSocket is healthy, send immediately
            if ws_health.is_healthy and ws_health.health_score > 0.7:
                success = await self._send_websocket_message(enhanced_message)
                if success:
                    return True
            
            # WebSocket is degraded, queue message for retry
            await self._queue_websocket_message(enhanced_message)
            
            # Start background retry process if not already running
            await self._ensure_websocket_retry_task()
            
            logger.info(f"ðŸ“¤ WebSocket message queued for resilient delivery")
            return True
            
        except Exception as e:
            logger.error(f"ðŸš¨ WebSocket resilience management failed: {str(e)}")
            
            # Emergency queue the message
            await self._emergency_queue_websocket_message(investigation_id, message)
            return False
    
    async def get_cached_intelligence_data(
        self,
        investigation_id: str,
        data_type: str,
        cache_strategy: CacheStrategy = CacheStrategy.MEDIUM_TERM
    ) -> Optional[Dict[str, Any]]:
        """
        Get cached intelligence data with quality assessment.
        
        Args:
            investigation_id: Investigation identifier
            data_type: Type of intelligence data
            cache_strategy: Caching strategy to use
            
        Returns:
            Cached data if available and valid
        """
        logger.info(f"ðŸ§  Retrieving cached intelligence data: {data_type}")
        
        try:
            # Generate cache key
            cache_key = self._generate_cache_key(investigation_id, data_type)
            
            # Get cached data
            cached_data = self.cached_data.get(cache_key)
            
            if cached_data:
                # Check if cache is still valid
                if await self._is_cache_valid(cached_data, cache_strategy):
                    # Update hit count and quality score
                    cached_data.hit_count += 1
                    cached_data.quality_score = await self._calculate_cache_quality(cached_data)
                    
                    logger.info(f"âœ… Cache hit for {data_type} (quality: {cached_data.quality_score:.2f})")
                    return {
                        "data": cached_data.data,
                        "cached": True,
                        "cache_age_seconds": (datetime.now() - cached_data.timestamp).total_seconds(),
                        "quality_score": cached_data.quality_score,
                        "hit_count": cached_data.hit_count
                    }
                else:
                    # Cache expired, remove it
                    del self.cached_data[cache_key]
                    logger.info(f"ðŸ—‘ï¸ Expired cache removed for {data_type}")
            
            logger.info(f"âŒ Cache miss for {data_type}")
            return None
            
        except Exception as e:
            logger.error(f"ðŸš¨ Failed to retrieve cached intelligence data: {str(e)}")
            return None
    
    async def cache_investigation_data(
        self,
        investigation_id: str,
        data_type: str,
        data: Any,
        cache_strategy: CacheStrategy = CacheStrategy.MEDIUM_TERM,
        metadata: Dict[str, Any] = None
    ) -> bool:
        """
        Cache investigation data with appropriate expiration strategy.
        
        Args:
            investigation_id: Investigation identifier
            data_type: Type of data to cache
            data: Data to cache
            cache_strategy: Caching strategy
            metadata: Additional cache metadata
            
        Returns:
            Success status of caching operation
        """
        logger.info(f"ðŸ’¾ Caching investigation data: {data_type} with {cache_strategy.value} strategy")
        
        try:
            # Generate cache key
            cache_key = self._generate_cache_key(investigation_id, data_type)
            
            # Calculate expiry based on strategy
            expiry = await self._calculate_cache_expiry(cache_strategy)
            
            # Create cached data record
            cached_data = CachedData(
                cache_key=cache_key,
                data=data,
                timestamp=datetime.now(),
                expiry=expiry,
                cache_strategy=cache_strategy,
                quality_score=1.0,  # New data starts with perfect quality
                metadata=metadata or {}
            )
            
            # Store cached data
            self.cached_data[cache_key] = cached_data
            
            # Clean up old cache entries
            await self._cleanup_expired_cache()
            
            logger.info(f"âœ… Cached {data_type} until {expiry.strftime('%Y-%m-%d %H:%M:%S')}")
            return True
            
        except Exception as e:
            logger.error(f"ðŸš¨ Failed to cache investigation data: {str(e)}")
            return False
    
    # Private helper methods
    
    def _initialize_service_health(self):
        """Initialize service health tracking for known services"""
        services = [
            ("anthropic_api", ServiceType.LLM_API),
            ("openai_api", ServiceType.LLM_API),
            ("database", ServiceType.DATABASE),
            ("redis_cache", ServiceType.CACHE),
            ("splunk_api", ServiceType.SPLUNK),
            ("threat_intel", ServiceType.THREAT_INTEL),
            ("websocket_manager", ServiceType.WEBSOCKET)
        ]
        
        for service_name, service_type in services:
            self.service_health[service_name] = ServiceHealth(
                service_name=service_name,
                service_type=service_type,
                is_healthy=True,
                last_check=datetime.now(),
                response_time_ms=100.0,
                error_rate=0.0,
                success_count=0,
                failure_count=0,
                consecutive_failures=0,
                health_score=1.0,
                degradation_level=0.0
            )
    
    def _initialize_fallback_strategies(self):
        """Initialize fallback strategies for different service types"""
        
        # LLM API fallback strategies
        self.fallback_strategies[ServiceType.LLM_API] = [
            FallbackStrategy(
                "anthropic_to_openai", ServiceType.LLM_API, 1,
                self._fallback_anthropic_to_openai, [],
                0.85, 3000, 1.2, "Switch from Anthropic to OpenAI"
            ),
            FallbackStrategy(
                "openai_to_anthropic", ServiceType.LLM_API, 2,
                self._fallback_openai_to_anthropic, [],
                0.80, 3500, 1.1, "Switch from OpenAI to Anthropic"
            ),
            FallbackStrategy(
                "rule_based_decision", ServiceType.LLM_API, 3,
                self._rule_based_decision_making, [],
                0.60, 500, 0.1, "Use rule-based decision making"
            )
        ]
        
        # Database fallback strategies
        self.fallback_strategies[ServiceType.DATABASE] = [
            FallbackStrategy(
                "read_only_replica", ServiceType.DATABASE, 1,
                self._use_read_replica, ["read_replica_available"],
                0.90, 800, 0.8, "Use read-only database replica"
            ),
            FallbackStrategy(
                "cached_data", ServiceType.DATABASE, 2,
                self._use_cached_database_data, [],
                0.70, 50, 0.1, "Use cached database data"
            )
        ]
    
    def _initialize_circuit_breakers(self):
        """Initialize circuit breakers for external services"""
        services = [
            "anthropic_api", "openai_api", "database", "redis_cache",
            "splunk_api", "threat_intel", "websocket_manager"
        ]
        
        for service in services:
            self.circuit_breakers[service] = CircuitBreaker(
                service_name=service,
                failure_threshold=5,
                recovery_timeout=60
            )
    
    async def _initialize_service_health_record(self, service_name: str) -> ServiceHealth:
        """Initialize health record for unknown service"""
        
        # Try to determine service type from name
        service_type = ServiceType.EXTERNAL_API
        if "llm" in service_name or "api" in service_name:
            service_type = ServiceType.LLM_API
        elif "database" in service_name or "db" in service_name:
            service_type = ServiceType.DATABASE
        elif "cache" in service_name or "redis" in service_name:
            service_type = ServiceType.CACHE
        elif "websocket" in service_name or "ws" in service_name:
            service_type = ServiceType.WEBSOCKET
        
        return ServiceHealth(
            service_name=service_name,
            service_type=service_type,
            is_healthy=True,
            last_check=datetime.now(),
            response_time_ms=0.0,
            error_rate=0.0,
            success_count=0,
            failure_count=0,
            consecutive_failures=0,
            health_score=0.5,  # Unknown service starts with neutral health
            degradation_level=0.0
        )
    
    async def _proactive_health_check(self, service_name: str, health: ServiceHealth) -> ServiceHealth:
        """Perform proactive health check for service"""
        
        try:
            start_time = datetime.now()
            
            # Simulate health check (in real implementation, would ping actual service)
            if service_name == "database":
                # Database health check simulation
                health_check_result = await self._check_database_health()
            elif service_name in ["anthropic_api", "openai_api"]:
                # LLM API health check simulation
                health_check_result = await self._check_llm_api_health(service_name)
            else:
                # Generic service health check
                health_check_result = await self._check_generic_service_health(service_name)
            
            # Calculate response time
            response_time = (datetime.now() - start_time).total_seconds() * 1000
            
            # Update health record
            health.last_check = datetime.now()
            health.response_time_ms = response_time
            
            if health_check_result["healthy"]:
                health.is_healthy = True
                health.success_count += 1
                health.consecutive_failures = 0
            else:
                health.is_healthy = False
                health.failure_count += 1
                health.consecutive_failures += 1
            
            # Update error rate
            total_checks = health.success_count + health.failure_count
            health.error_rate = health.failure_count / total_checks if total_checks > 0 else 0
            
        except Exception as e:
            logger.warning(f"âš ï¸ Health check failed for {service_name}: {str(e)}")
            health.is_healthy = False
            health.failure_count += 1
            health.consecutive_failures += 1
        
        return health
    
    async def _predictive_failure_analysis(self, service_name: str, health: ServiceHealth) -> ServiceHealth:
        """Perform predictive failure analysis using patterns"""
        
        # Get recent failure patterns
        patterns = self.failure_patterns[service_name]
        
        if len(patterns) >= 10:  # Need sufficient data for prediction
            # Simple prediction based on recent failure rate
            recent_failures = sum(1 for p in list(patterns)[-10:] if not p["healthy"])
            failure_rate = recent_failures / 10
            
            # Predict potential failure if rate is increasing
            if failure_rate > 0.3:
                health.metadata["predicted_failure_risk"] = "high"
                health.degradation_level = max(health.degradation_level, failure_rate)
            elif failure_rate > 0.1:
                health.metadata["predicted_failure_risk"] = "medium"
            else:
                health.metadata["predicted_failure_risk"] = "low"
        
        return health
    
    async def _calculate_health_score(self, health: ServiceHealth) -> float:
        """Calculate overall health score from multiple factors"""
        
        # Base score from success rate
        total_requests = health.success_count + health.failure_count
        success_rate = health.success_count / total_requests if total_requests > 0 else 1.0
        
        # Response time factor (normalized, assume 1000ms is baseline)
        response_factor = max(0.1, min(1.0, 1000.0 / max(health.response_time_ms, 100)))
        
        # Consecutive failures penalty
        consecutive_penalty = max(0.1, 1.0 - (health.consecutive_failures * 0.2))
        
        # Combined health score
        health_score = success_rate * 0.5 + response_factor * 0.3 + consecutive_penalty * 0.2
        
        return max(0.0, min(1.0, health_score))
    
    async def _calculate_degradation_level(self, health: ServiceHealth) -> float:
        """Calculate service degradation level"""
        
        if not health.is_healthy:
            return min(1.0, health.consecutive_failures * 0.2)
        
        # Degradation based on error rate and response time
        error_degradation = health.error_rate
        response_degradation = max(0.0, (health.response_time_ms - 1000) / 5000)
        
        return max(0.0, min(1.0, error_degradation + response_degradation))
    
    # Service health check implementations (simulated)
    
    async def _check_database_health(self) -> Dict[str, Any]:
        """Simulate database health check"""
        return {"healthy": True, "connections": 10, "query_time": 50}
    
    async def _check_llm_api_health(self, service_name: str) -> Dict[str, Any]:
        """Simulate LLM API health check"""
        return {"healthy": True, "quota_remaining": 1000, "rate_limit": "normal"}
    
    async def _check_generic_service_health(self, service_name: str) -> Dict[str, Any]:
        """Simulate generic service health check"""
        return {"healthy": True, "status": "operational"}
    
    # Fallback strategy implementations
    
    async def _fallback_anthropic_to_openai(self, investigation_id: str, prompt: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Fallback from Anthropic to OpenAI API"""
        return {
            "success": True,
            "response": "OpenAI fallback response",
            "confidence_score": 0.8,
            "processing_time": 3000
        }
    
    async def _fallback_openai_to_anthropic(self, investigation_id: str, prompt: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Fallback from OpenAI to Anthropic API"""
        return {
            "success": True,
            "response": "Anthropic fallback response",
            "confidence_score": 0.8,
            "processing_time": 3500
        }
    
    async def _rule_based_decision_making(self, investigation_id: str, prompt: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Rule-based decision making as LLM fallback"""
        return {
            "success": True,
            "response": "Rule-based analysis result",
            "confidence_score": 0.6,
            "processing_time": 500
        }
    
    # Database resilience implementations
    
    async def _execute_database_operation(self, operation: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """Execute database operation (simulated)"""
        return {"success": True, "operation": operation, "data": data}
    
    async def _handle_database_degradation(
        self,
        investigation_id: str,
        operation: str,
        data: Dict[str, Any],
        health: ServiceHealth,
        use_cache: bool
    ) -> Dict[str, Any]:
        """Handle database degradation with fallback strategies"""
        
        # Try cached data first
        if use_cache:
            cached_result = await self._get_cached_database_result(investigation_id, operation)
            if cached_result:
                return cached_result
        
        # Try read replica for read operations
        if operation.startswith("read"):
            replica_result = await self._try_read_replica(operation, data)
            if replica_result:
                return replica_result
        
        # Return degraded response
        return {
            "success": True,
            "data": {},
            "degraded": True,
            "reason": f"Database health score: {health.health_score:.2f}"
        }
    
    # WebSocket resilience implementations
    
    async def _send_websocket_message(self, message: Dict[str, Any]) -> bool:
        """Send WebSocket message - removed per spec 005, using polling instead"""
        # WebSocket messaging removed, replaced by polling-based updates
        return True
    
    async def _queue_websocket_message(self, message: Dict[str, Any]):
        """Queue WebSocket message for retry"""
        self.websocket_queue.append(message)
    
    async def _ensure_websocket_retry_task(self):
        """Ensure WebSocket retry background task is running"""
        if not hasattr(self, '_websocket_retry_task') or self._websocket_retry_task.done():
            self._websocket_retry_task = asyncio.create_task(self._websocket_retry_loop())
    
    async def _websocket_retry_loop(self):
        """Background loop for WebSocket message retries"""
        while True:
            try:
                if self.websocket_queue:
                    message = self.websocket_queue.popleft()
                    
                    # Try to send message
                    success = await self._send_websocket_message(message)
                    
                    if not success and message["retry_count"] < message["max_retries"]:
                        # Increment retry count and requeue
                        message["retry_count"] += 1
                        self.websocket_queue.append(message)
                
                await asyncio.sleep(1)  # Check queue every second
                
            except Exception as e:
                logger.error(f"WebSocket retry loop error: {str(e)}")
                await asyncio.sleep(5)  # Longer delay on error
    
    # Cache management implementations
    
    def _generate_cache_key(self, investigation_id: str, data_type: str) -> str:
        """Generate cache key for investigation data"""
        content = f"{investigation_id}_{data_type}"
        return hashlib.md5(content.encode()).hexdigest()[:16]
    
    async def _calculate_cache_expiry(self, strategy: CacheStrategy) -> datetime:
        """Calculate cache expiry based on strategy"""
        now = datetime.now()
        
        if strategy == CacheStrategy.SHORT_TERM:
            return now + timedelta(minutes=15)
        elif strategy == CacheStrategy.MEDIUM_TERM:
            return now + timedelta(hours=2)
        elif strategy == CacheStrategy.LONG_TERM:
            return now + timedelta(days=1)
        elif strategy == CacheStrategy.PERSISTENT:
            return now + timedelta(days=365)  # Effectively persistent
        else:  # NO_CACHE
            return now  # Immediate expiry
    
    async def _is_cache_valid(self, cached_data: CachedData, strategy: CacheStrategy) -> bool:
        """Check if cached data is still valid"""
        return datetime.now() < cached_data.expiry
    
    async def _calculate_cache_quality(self, cached_data: CachedData) -> float:
        """Calculate cache data quality score"""
        age_seconds = (datetime.now() - cached_data.timestamp).total_seconds()
        
        # Quality degrades over time
        if cached_data.cache_strategy == CacheStrategy.SHORT_TERM:
            max_age = 900  # 15 minutes
        elif cached_data.cache_strategy == CacheStrategy.MEDIUM_TERM:
            max_age = 7200  # 2 hours
        else:
            max_age = 86400  # 24 hours
        
        quality = max(0.1, 1.0 - (age_seconds / max_age))
        return min(1.0, quality)
    
    async def _cleanup_expired_cache(self):
        """Clean up expired cache entries"""
        now = datetime.now()
        expired_keys = [
            key for key, cached_data in self.cached_data.items()
            if now > cached_data.expiry
        ]
        
        for key in expired_keys:
            del self.cached_data[key]
        
        if expired_keys:
            logger.info(f"ðŸ—‘ï¸ Cleaned up {len(expired_keys)} expired cache entries")
    
    # Utility and helper methods
    
    async def _update_failure_patterns(self, service_name: str, health: ServiceHealth):
        """Update failure patterns for predictive analysis"""
        pattern = {
            "timestamp": datetime.now().isoformat(),
            "healthy": health.is_healthy,
            "response_time": health.response_time_ms,
            "consecutive_failures": health.consecutive_failures
        }
        
        self.failure_patterns[service_name].append(pattern)
    
    async def _trigger_circuit_breaker(self, service_name: str, health: ServiceHealth):
        """Trigger circuit breaker for failed service"""
        circuit_breaker = self.circuit_breakers.get(service_name)
        if circuit_breaker:
            circuit_breaker.state = CircuitBreakerState.OPEN
            circuit_breaker.failure_count = health.failure_count
            circuit_breaker.last_failure_time = datetime.now()
            
            logger.warning(f"ðŸš¨ Circuit breaker OPEN for {service_name}")
    
    async def _check_strategy_prerequisites(self, strategy: FallbackStrategy, context: Dict[str, Any]) -> bool:
        """Check if fallback strategy prerequisites are met"""
        for prerequisite in strategy.prerequisites:
            if prerequisite not in context or not context[prerequisite]:
                return False
        return True
    
    async def _record_fallback_success(self, strategy: FallbackStrategy, investigation_id: str):
        """Record successful fallback strategy execution"""
        strategy.success_rate = min(1.0, strategy.success_rate + 0.01)
        logger.info(f"ðŸ“ˆ Fallback strategy {strategy.strategy_id} success rate: {strategy.success_rate:.2f}")
    
    # Emergency response methods
    
    async def _create_emergency_health_record(self, service_name: str) -> ServiceHealth:
        """Create emergency health record for failed service"""
        return ServiceHealth(
            service_name=service_name,
            service_type=ServiceType.EXTERNAL_API,
            is_healthy=False,
            last_check=datetime.now(),
            response_time_ms=0.0,
            error_rate=1.0,
            success_count=0,
            failure_count=1,
            consecutive_failures=1,
            health_score=0.0,
            degradation_level=1.0,
            metadata={"emergency_record": True}
        )
    
    async def _generate_rule_based_llm_response(self, investigation_id: str, prompt: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Generate rule-based LLM response when all LLM APIs fail"""
        return {
            "success": True,
            "response": "Rule-based analysis completed due to LLM API unavailability",
            "fallback_strategy": "rule_based_fallback",
            "confidence_score": 0.5,
            "processing_time": 100,
            "metadata": {
                "all_llm_apis_failed": True,
                "fallback_type": "rule_based"
            }
        }
    
    async def _create_emergency_llm_response(self, investigation_id: str, prompt: str) -> Dict[str, Any]:
        """Create emergency LLM response when everything fails"""
        return {
            "success": False,
            "response": "Emergency response: All LLM services unavailable",
            "fallback_strategy": "emergency",
            "confidence_score": 0.1,
            "processing_time": 0,
            "error": "Complete LLM service failure"
        }
    
    async def _get_cached_database_result(self, investigation_id: str, operation: str) -> Optional[Dict[str, Any]]:
        """Get cached database result"""
        cache_key = self._generate_cache_key(investigation_id, f"db_{operation}")
        cached_data = self.cached_data.get(cache_key)
        
        if cached_data and await self._is_cache_valid(cached_data, cached_data.cache_strategy):
            return {
                "success": True,
                "data": cached_data.data,
                "cached": True,
                "cache_age": (datetime.now() - cached_data.timestamp).total_seconds()
            }
        
        return None
    
    async def _cache_database_result(self, investigation_id: str, operation: str, result: Dict[str, Any]):
        """Cache database operation result"""
        await self.cache_investigation_data(
            investigation_id, f"db_{operation}", result,
            CacheStrategy.MEDIUM_TERM, {"operation_type": operation}
        )
    
    async def _create_database_emergency_response(self, investigation_id: str, operation: str) -> Dict[str, Any]:
        """Create emergency database response"""
        return {
            "success": False,
            "data": {},
            "error": "Database unavailable and no cached data",
            "operation": operation,
            "emergency": True
        }
    
    async def _try_read_replica(self, operation: str, data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Try to use read replica for database operations"""
        # Simulated read replica usage
        if operation.startswith("read"):
            return {
                "success": True,
                "data": data,
                "source": "read_replica"
            }
        return None
    
    async def _emergency_queue_websocket_message(self, investigation_id: str, message: Dict[str, Any]):
        """Emergency queue WebSocket message"""
        emergency_message = {
            "investigation_id": investigation_id,
            "content": str(message),
            "emergency": True,
            "timestamp": datetime.now().isoformat(),
            "retry_count": 0,
            "max_retries": 5
        }
        self.websocket_queue.append(emergency_message)


# Global service resilience manager instance
_service_resilience_manager_instance = None

def get_service_resilience_manager() -> ServiceResilienceManager:
    """Get global service resilience manager instance"""
    global _service_resilience_manager_instance
    if _service_resilience_manager_instance is None:
        _service_resilience_manager_instance = ServiceResilienceManager()
    return _service_resilience_manager_instance