# Fraud Detection Prompt Templates v14
# Feature: 026-llm-training-pipeline
# ITERATION 11: Balanced approach with additive signal scoring
#
# LEARNINGS FROM v12 AND v13:
# - v12: Baseline 0.50, threshold 0.45 → 76% recall, 0.75% precision (2115 FP)
# - v13: Baseline 0.30, threshold 0.60 with COMBINATORIAL → 0% recall (missed ALL fraud)
#
# KEY INSIGHT FROM v13 FEEDBACK:
# - Fraudsters look NORMAL: 1-5 devices, moderate transactions, reasonable GMV
# - The "combinatorial" requirement was too strict - no fraud case triggered it
# - Need ADDITIVE signals, not COMBINATORIAL gates
#
# v14 Strategy:
# 1. Baseline 0.35 (between v12's 0.50 and v13's 0.30)
# 2. Threshold 0.50 (lower than v13's 0.60)
# 3. Use ADDITIVE signals (each signal adds risk independently)
# 4. Focus on RATIOS and ANOMALIES, not absolute thresholds

version: v14
created_at: "2024-12-12"
description: "Balanced additive scoring with ratio-based anomaly detection"

# System prompt - ADDITIVE approach with ratio signals
system_prompt: |
  You are an expert fraud detection analyst predicting FUTURE fraud risk.

  ## Critical Context
  - Base rate: ~0.7-1% of entities commit fraud (rare but costly)
  - Fraudsters often MIMIC normal users (1-5 devices, moderate GMV)
  - Missing fraud is costly - prefer slightly higher recall over precision
  - Use ADDITIVE scoring - each signal adds independently

  ## ADDITIVE Scoring System

  **Baseline: 0.35** (slightly below neutral)

  ### FRAUD SIGNALS (Add risk - INDEPENDENT, not combinatorial):

  **Device/IP Anomalies** (add each that applies):
  - devices > 3 → +0.08
  - devices > 5 → +0.10 (additional)
  - ips > devices * 2 → +0.08 (network diversity exceeds device diversity)
  - devices >= transactions * 0.5 → +0.10 (high device-to-tx ratio)

  **Value Anomalies** (add each that applies):
  - total_gmv > $1000 AND transactions < 10 → +0.12 (high value, low activity)
  - avg_tx_value > $100 → +0.06
  - avg_tx_value > $200 → +0.08 (additional)
  - std_tx_value > avg_tx_value → +0.08 (high variance relative to mean)

  **Behavioral Anomalies** (add each that applies):
  - transactions < 5 AND gmv > $200 → +0.10 (new account, decent spend)
  - transactions < 10 AND devices > 2 → +0.08 (many devices for few txs)
  - merchants == 1 AND transactions > 5 → +0.05 (single merchant focus)

  ### LEGITIMATE SIGNALS (Subtract risk - each independently):
  - transactions > 30 AND devices <= 2 → -0.10 (established, stable)
  - transactions > 15 AND std_tx_value < avg_tx_value * 0.5 → -0.08 (consistent)
  - devices == 1 AND ips <= 3 → -0.06 (stable setup)
  - avg_tx_value < $40 AND transactions > 10 → -0.05 (typical buyer)

  ### Scoring Rules:
  1. Start at 0.35
  2. Add ALL fraud signals that apply (independent)
  3. Subtract ALL legitimate signals that apply
  4. Cap final score at [0.0, 1.0]
  5. Predict FRAUD if score >= 0.50, else LEGITIMATE

  ### Score Interpretation:
  - 0.00-0.35: Low risk
  - 0.35-0.50: Below threshold - predict LEGITIMATE
  - 0.50-0.70: Elevated risk - predict FRAUD
  - 0.70-1.00: High risk - predict FRAUD

  ## Decision Threshold
  - risk_score >= 0.50 → predict FRAUD
  - risk_score < 0.50 → predict LEGITIMATE

  ## Output Format
  Provide JSON:
  ```json
  {
    "risk_score": <float 0.0-1.0>,
    "confidence": <float 0.0-1.0>,
    "prediction": "<FRAUD|LEGITIMATE>",
    "reasoning": "<brief explanation>",
    "key_indicators": [<list of signals that influenced the score>],
    "risk_factors": {
      "device_risk": <float 0.0-1.0>,
      "velocity_risk": <float 0.0-1.0>,
      "value_risk": <float 0.0-1.0>,
      "pattern_risk": <float 0.0-1.0>
    }
  }
  ```

# Main fraud analysis prompt
fraud_analysis_prompt: |
  Analyze this entity for FUTURE fraud risk.

  ADDITIVE SCORING (baseline 0.35, threshold 0.50):
  1. Start at 0.35
  2. Add each fraud signal that applies (independently)
  3. Subtract each legitimate signal that applies
  4. Predict FRAUD if final score >= 0.50

  ## Entity Information
  - Entity Type: {entity_type}
  - Entity Value: {entity_value}
  - Merchant: {merchant_name}

  ## Behavioral Features (Feature Period)
  - Total Transactions: {total_transactions}
  - Total GMV: ${total_gmv}
  - Average Transaction Value: ${avg_tx_value}
  - Transaction Value Std Dev: ${std_tx_value}
  - Unique Devices: {unique_devices}
  - Unique IPs: {unique_ips}
  - Unique Merchants: {unique_merchants}
  - Date Range: {date_range}

  ## Analysis Steps (ADDITIVE - check each independently):

  1. **Device/IP Signals** (add each that applies):
     - devices > 3: +0.08
     - devices > 5: +0.10 additional
     - ips > devices * 2: +0.08
     - devices >= transactions * 0.5: +0.10

  2. **Value Signals** (add each that applies):
     - GMV > $1000 AND txs < 10: +0.12
     - avg_tx_value > $100: +0.06
     - avg_tx_value > $200: +0.08 additional
     - std_tx_value > avg_tx_value: +0.08

  3. **Behavioral Signals** (add each that applies):
     - txs < 5 AND GMV > $200: +0.10
     - txs < 10 AND devices > 2: +0.08
     - merchants == 1 AND txs > 5: +0.05

  4. **Legitimate Signals** (subtract each that applies):
     - txs > 30 AND devices <= 2: -0.10
     - txs > 15 AND std < avg * 0.5: -0.08
     - devices == 1 AND ips <= 3: -0.06
     - avg < $40 AND txs > 10: -0.05

  CALCULATE: Sum all adjustments from 0.35 baseline
  DECIDE: >= 0.50 = FRAUD, < 0.50 = LEGITIMATE

  Provide your analysis in JSON format:
  ```json
  {{
    "risk_score": <float 0.0-1.0>,
    "confidence": <float 0.0-1.0>,
    "prediction": "<FRAUD|LEGITIMATE>",
    "reasoning": "<explain which signals added/subtracted and the calculation>",
    "key_indicators": [<list of detected signals with their +/- values>],
    "risk_factors": {{
      "device_risk": <float 0.0-1.0>,
      "velocity_risk": <float 0.0-1.0>,
      "value_risk": <float 0.0-1.0>,
      "pattern_risk": <float 0.0-1.0>
    }}
  }}
  ```

# Template for fraud indicators
fraud_indicators_template: |
  ## Behavioral Risk Indicators
  - Total Transactions: {total_transactions}
  - Total GMV: ${total_gmv}
  - Average Transaction Value: ${avg_tx_value}
  - Transaction Value Std Dev: ${std_tx_value}
  - Unique Devices: {device_count}
  - Unique IPs: {ip_count}
  - Unique Merchants: {merchant_count}

# Template for velocity analysis
velocity_analysis_template: |
  ## Transaction Velocity Patterns
  - Transaction Count: {total_transactions}
  - Average Transaction Value: ${avg_tx_value}
  - Value Variance (Std Dev): ${std_tx_value}
  - Activity Span: {first_tx_date} to {last_tx_date}

# Template for geographic analysis
geographic_analysis_template: |
  ## Network Diversity
  - Unique IP Addresses: {ip_count}
  - IP per Transaction Ratio: {ip_ratio}

# Template for device/network analysis
device_analysis_template: |
  ## Device Fingerprint Analysis
  - Unique Devices: {device_count}
  - Unique IPs: {ip_count}
  - Multi-Device Pattern: {multi_device}

# Template for historical patterns
historical_patterns_template: |
  ## Account History
  - First Transaction: {first_tx_date}
  - Last Transaction: {last_tx_date}
  - Transaction Count: {total_transactions}
  - Merchants Used: {merchant_count}

# Batch analysis prompt
batch_analysis_prompt: |
  Analyze {entity_count} entities for future fraud risk.

  Use additive scoring (baseline 0.35, threshold 0.50).
  Add each fraud signal independently, subtract legitimate signals.

  {entities_data}

  Provide JSON array:
  ```json
  [
    {{
      "entity_id": "<entity identifier>",
      "risk_score": <float 0.0-1.0>,
      "confidence": <float 0.0-1.0>,
      "prediction": "<FRAUD|LEGITIMATE>",
      "reasoning": "<brief explanation>"
    }}
  ]
  ```

# Feedback analysis prompt
feedback_analysis_prompt: |
  The following prediction was incorrect:

  ## Original Prediction
  - Entity: {entity_value}
  - Predicted: {predicted_label}
  - Actual: {actual_label}
  - Risk Score: {risk_score}

  ## Entity Behavioral Data
  {entity_data}

  ## Actual Outcome
  - Committed Fraud: {committed_fraud}

  Analyze the error:
  ```json
  {{
    "error_type": "<false_positive|false_negative>",
    "likely_cause": "<explanation>",
    "missed_patterns": [<patterns that should have been weighted differently>],
    "suggested_adjustments": {{
      "signal_adjustments": {{<suggested weight changes>}},
      "threshold_adjustment": <suggested change>
    }}
  }}
  ```
