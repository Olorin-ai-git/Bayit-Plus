# Fraud Detection Prompt Templates v11
# Feature: 026-llm-training-pipeline
# ITERATION 8: Balanced scoring with neutral baseline
#
# PROBLEM WITH v9/v10: Baseline too low (0.30-0.35) + heavy legitimate deductions
# resulted in most scores being 0.10-0.30, way below any threshold.
#
# v11 Strategy:
# 1. Neutral baseline (0.50) - start in the middle
# 2. Smaller deductions for legitimate signals (-0.05 to -0.10)
# 3. Clear fraud signals still add +0.15 to +0.25
# 4. Threshold at 0.55 - fraud needs ONE clear signal or TWO moderate ones

version: v11
created_at: "2024-12-10"
description: "Balanced scoring with neutral baseline and moderate adjustments"

# System prompt - BALANCED approach with neutral baseline
system_prompt: |
  You are an expert fraud detection analyst predicting FUTURE fraud risk.

  IMPORTANT: You have NO information about past fraud - only behavioral patterns.
  You must predict which entities WILL commit fraud in the observation period.

  ## The Challenge
  - Fraud is rare (~0.7% of entities)
  - But we need to CATCH fraud, not just minimize false positives
  - Balance: Flag suspicious patterns without flagging normal users

  ## Scoring System

  **Start at NEUTRAL baseline: risk_score = 0.50**

  ### Add Risk for Fraud Signals:
  - device_count >= 5 AND ip_count >= 8 → +0.25 (fraud ring pattern)
  - std_tx_value > avg_tx_value * 2 → +0.20 (testing card limits)
  - device_count >= 4 AND total_transactions < 10 → +0.15 (new accounts, many devices)
  - ip_count >= 6 with few transactions → +0.15 (IP hopping)
  - avg_tx_value > $500 with high std → +0.10 (high-value fraud attempt)

  ### Subtract Risk for Legitimate Signals:
  - device_count == 1 AND ip_count <= 2 → -0.10 (stable user)
  - total_transactions > 20 with device_count <= 2 → -0.10 (loyal customer)
  - std_tx_value < avg_tx_value * 0.3 → -0.05 (very consistent spending)
  - Single merchant focus → -0.05 (established relationship)

  ### Score Interpretation:
  - 0.00-0.35: Low risk (strong legitimate signals)
  - 0.35-0.50: Below average risk (some legitimate signals)
  - 0.50-0.55: Neutral/Uncertain
  - 0.55-0.70: Elevated risk (some fraud signals)
  - 0.70-1.00: High risk (multiple fraud signals)

  ## Decision Threshold
  - risk_score >= 0.55 → predict FRAUD
  - risk_score < 0.55 → predict LEGITIMATE

  ## Output Format
  Provide JSON:
  ```json
  {
    "risk_score": <float 0.0-1.0>,
    "confidence": <float 0.0-1.0>,
    "prediction": "<FRAUD|LEGITIMATE>",
    "reasoning": "<brief explanation>",
    "key_indicators": [<list of signals that influenced the score>],
    "risk_factors": {
      "device_risk": <float 0.0-1.0>,
      "velocity_risk": <float 0.0-1.0>,
      "value_risk": <float 0.0-1.0>,
      "pattern_risk": <float 0.0-1.0>
    }
  }
  ```

# Main fraud analysis prompt
fraud_analysis_prompt: |
  Analyze this entity for FUTURE fraud risk.

  SCORING RULES:
  1. Start at 0.50 (neutral)
  2. Add risk for fraud signals (+0.10 to +0.25)
  3. Subtract risk for legitimate signals (-0.05 to -0.10)
  4. Predict FRAUD if final score >= 0.55

  ## Entity Information
  - Entity Type: {entity_type}
  - Entity Value: {entity_value}
  - Merchant: {merchant_name}

  ## Behavioral Features (Feature Period)
  - Total Transactions: {total_transactions}
  - Total GMV: ${total_gmv}
  - Average Transaction Value: ${avg_tx_value}
  - Transaction Value Std Dev: ${std_tx_value}
  - Unique Devices: {unique_devices}
  - Unique IPs: {unique_ips}
  - Unique Merchants: {unique_merchants}
  - Date Range: {date_range}

  ## Analysis Steps:

  1. **Calculate value variance ratio**: std / avg
     - If > 2.0: Add +0.20 (testing limits)
     - If < 0.3: Subtract -0.05 (consistent)

  2. **Check device/IP pattern**:
     - devices >= 5 AND ips >= 8: Add +0.25 (fraud ring)
     - devices >= 4 with < 10 txs: Add +0.15 (suspicious new account)
     - devices == 1 AND ips <= 2: Subtract -0.10 (stable)

  3. **Check transaction velocity**:
     - ips >= 6 with few txs: Add +0.15 (IP hopping)
     - txs > 20 with devices <= 2: Subtract -0.10 (loyal)

  4. **Check value patterns**:
     - avg > $500 with high variance: Add +0.10

  5. **Apply merchant focus**:
     - Single merchant: Subtract -0.05

  FINAL: Sum all adjustments from baseline 0.50

  Provide your analysis in JSON format:
  ```json
  {{
    "risk_score": <float 0.0-1.0>,
    "confidence": <float 0.0-1.0>,
    "prediction": "<FRAUD|LEGITIMATE>",
    "reasoning": "<explain which signals affected the score>",
    "key_indicators": [<list of detected signals>],
    "risk_factors": {{
      "device_risk": <float 0.0-1.0>,
      "velocity_risk": <float 0.0-1.0>,
      "value_risk": <float 0.0-1.0>,
      "pattern_risk": <float 0.0-1.0>
    }}
  }}
  ```

# Template for fraud indicators
fraud_indicators_template: |
  ## Behavioral Risk Indicators
  - Total Transactions: {total_transactions}
  - Total GMV: ${total_gmv}
  - Average Transaction Value: ${avg_tx_value}
  - Transaction Value Std Dev: ${std_tx_value}
  - Unique Devices: {device_count}
  - Unique IPs: {ip_count}
  - Unique Merchants: {merchant_count}

# Template for velocity analysis
velocity_analysis_template: |
  ## Transaction Velocity Patterns
  - Transaction Count: {total_transactions}
  - Average Transaction Value: ${avg_tx_value}
  - Value Variance (Std Dev): ${std_tx_value}
  - Activity Span: {first_tx_date} to {last_tx_date}

# Template for geographic analysis
geographic_analysis_template: |
  ## Network Diversity
  - Unique IP Addresses: {ip_count}
  - IP per Transaction Ratio: {ip_ratio}

# Template for device/network analysis
device_analysis_template: |
  ## Device Fingerprint Analysis
  - Unique Devices: {device_count}
  - Unique IPs: {ip_count}
  - Multi-Device Pattern: {multi_device}

# Template for historical patterns
historical_patterns_template: |
  ## Account History
  - First Transaction: {first_tx_date}
  - Last Transaction: {last_tx_date}
  - Transaction Count: {total_transactions}
  - Merchants Used: {merchant_count}

# Batch analysis prompt
batch_analysis_prompt: |
  Analyze {entity_count} entities for future fraud risk.

  Use neutral baseline (0.50) and adjust based on signals.
  Threshold: >= 0.55 = FRAUD

  {entities_data}

  Provide JSON array:
  ```json
  [
    {{
      "entity_id": "<entity identifier>",
      "risk_score": <float 0.0-1.0>,
      "confidence": <float 0.0-1.0>,
      "prediction": "<FRAUD|LEGITIMATE>",
      "reasoning": "<brief explanation>"
    }}
  ]
  ```

# Feedback analysis prompt
feedback_analysis_prompt: |
  The following prediction was incorrect:

  ## Original Prediction
  - Entity: {entity_value}
  - Predicted: {predicted_label}
  - Actual: {actual_label}
  - Risk Score: {risk_score}

  ## Entity Behavioral Data
  {entity_data}

  ## Actual Outcome
  - Committed Fraud: {committed_fraud}

  Analyze the error:
  ```json
  {{
    "error_type": "<false_positive|false_negative>",
    "likely_cause": "<explanation>",
    "missed_patterns": [<patterns that should have been weighted differently>],
    "suggested_adjustments": {{
      "signal_adjustments": {{<suggested weight changes>}},
      "threshold_adjustment": <suggested change>
    }}
  }}
  ```
