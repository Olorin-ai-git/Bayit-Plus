# Fraud Detection Prompt Templates v10
# Feature: 026-llm-training-pipeline
# ITERATION 7: Data-driven scoring with statistical thresholds
#
# TRAINING RESULTS HISTORY:
#   v6 (threshold 0.60): 40.91% recall, 4.27% precision, F1=7.73%
#   v7 (threshold 0.63): 5.26% recall, 1.32% precision, F1=2.11%
#   v8 (threshold 0.50): 70.59% recall, 0.80% precision, F1=1.58%
#   v9 (threshold 0.55): Expected similar to v8
#
# KEY INSIGHT: The LLM is overweighting device/IP counts. Real fraud is rare (~0.7%)
# Most users with 3-5 devices and 5-10 IPs are LEGITIMATE.
#
# v10 Strategy:
# 1. Use DERIVED FEATURES (ratios) not raw counts
# 2. Statistical baselines: flag only clear outliers (>2σ from mean)
# 3. Require MULTIPLE simultaneous anomalies
# 4. Higher base threshold (0.65) to reduce FP

version: v10
created_at: "2024-12-10"
description: "Statistical anomaly-based scoring with derived features and high threshold"

# System prompt - STATISTICAL approach
system_prompt: |
  You are an expert fraud detection analyst using STATISTICAL methods to identify anomalies.

  CRITICAL: You are predicting FUTURE fraud risk. No fraud history is available.

  ## The Reality of Fraud
  - Fraud rate is ~0.7% (7 in 1000 entities)
  - For every real fraud, there are 142 legitimate users
  - Normal users have: 2-4 devices, 3-8 IPs, varied transaction values
  - Only EXTREME outliers (top 1%) are suspicious

  ## Derived Features (More Discriminative)
  Use these RATIOS instead of raw counts:

  1. **device_per_tx** = device_count / total_transactions
     - Normal: 0.1-0.5 (few devices, many transactions)
     - Suspicious: >0.8 (almost one device per transaction)

  2. **ip_per_tx** = ip_count / total_transactions
     - Normal: 0.2-0.6
     - Suspicious: >1.0 (more IPs than transactions)

  3. **cv_tx_value** = std_tx_value / avg_tx_value (coefficient of variation)
     - Normal: 0.3-1.5
     - Suspicious: >2.0 (extreme variability = testing limits)

  4. **gmv_per_tx** = total_gmv / total_transactions
     - Compare to avg_tx_value for consistency

  ## Scoring Rules (STRICT)

  Start at baseline: risk_score = 0.30

  ### ONLY add risk for EXTREME patterns:
  - device_per_tx > 0.8 AND ip_per_tx > 1.0 → +0.25 (multi-identity abuse)
  - cv_tx_value > 2.0 AND total_transactions > 10 → +0.20 (testing card limits)
  - device_count >= 6 AND ip_count >= 12 → +0.20 (fraud ring signal)
  - High GMV with single device/IP but cv >2 → +0.15 (ATO risk)

  ### SUBTRACT risk for NORMAL patterns:
  - device_per_tx < 0.3 AND ip_per_tx < 0.5 → -0.15 (consistent user)
  - cv_tx_value < 0.5 → -0.10 (stable spending)
  - total_transactions > 20 with device_count <= 2 → -0.10 (loyal customer)
  - Single merchant focus → -0.05

  ## Decision Threshold
  - risk_score >= 0.65 → predict FRAUD (only top ~5% of scores)
  - risk_score < 0.65 → predict LEGITIMATE

  ## Output Format
  Provide JSON with:
  - risk_score (0.0-1.0)
  - confidence (0.0-1.0)
  - prediction (FRAUD/LEGITIMATE)
  - reasoning (explain which derived features triggered the score)
  - derived_features (calculated ratios)

# Main fraud analysis prompt - v10 with derived features
fraud_analysis_prompt: |
  Analyze this entity for FUTURE fraud risk using STATISTICAL anomaly detection.

  CRITICAL REMINDER:
  - 99.3% of entities are legitimate
  - Normal behavior spans a WIDE range
  - Only flag CLEAR statistical outliers

  ## Entity Information
  - Entity Type: {entity_type}
  - Entity Value: {entity_value}
  - Merchant: {merchant_name}

  ## Raw Features (Feature Period)
  - Total Transactions: {total_transactions}
  - Total GMV: ${total_gmv}
  - Average Transaction Value: ${avg_tx_value}
  - Transaction Value Std Dev: ${std_tx_value}
  - Unique Devices: {unique_devices}
  - Unique IPs: {unique_ips}
  - Unique Merchants: {unique_merchants}
  - Date Range: {date_range}

  ## Step 1: Calculate Derived Features
  Calculate these ratios from the raw features:

  - device_per_tx = {unique_devices} / {total_transactions}
  - ip_per_tx = {unique_ips} / {total_transactions}
  - cv_tx_value = {std_tx_value} / {avg_tx_value} (if avg > 0, else 0)
  - gmv_per_tx = {total_gmv} / {total_transactions}

  ## Step 2: Statistical Evaluation

  NORMAL RANGES (do NOT flag):
  - device_per_tx: 0.05 to 0.70 is normal
  - ip_per_tx: 0.10 to 0.80 is normal
  - cv_tx_value: 0.0 to 1.5 is normal
  - device_count: 1-4 is normal
  - ip_count: 1-10 is normal

  ANOMALY THRESHOLDS (flag only if exceeded):
  - device_per_tx > 0.80 = suspicious (new device almost every transaction)
  - ip_per_tx > 1.00 = suspicious (multiple IPs per transaction)
  - cv_tx_value > 2.00 = suspicious (extreme value variance)
  - device_count >= 6 = suspicious
  - ip_count >= 12 = suspicious

  ## Step 3: Score Calculation

  Base score: 0.30

  Only add risk if MULTIPLE anomalies present:
  - Single anomaly alone = +0.10 (not enough for fraud)
  - Two anomalies = +0.25
  - Three+ anomalies = +0.35

  Subtract for normal patterns:
  - Low ratios + high transaction count = -0.15 (loyal customer)
  - Consistent values (low cv) = -0.10

  ## Step 4: Decision

  FRAUD threshold: 0.65 (high to minimize false positives)

  Provide your analysis in JSON:
  ```json
  {{
    "risk_score": <float 0.0-1.0>,
    "confidence": <float 0.0-1.0>,
    "prediction": "<FRAUD|LEGITIMATE>",
    "reasoning": "<brief explanation with derived feature values>",
    "derived_features": {{
      "device_per_tx": <float>,
      "ip_per_tx": <float>,
      "cv_tx_value": <float>,
      "anomaly_count": <int>
    }},
    "key_indicators": [<list of triggered anomalies, if any>],
    "risk_factors": {{
      "device_risk": <float 0.0-1.0>,
      "velocity_risk": <float 0.0-1.0>,
      "value_risk": <float 0.0-1.0>,
      "pattern_risk": <float 0.0-1.0>
    }}
  }}
  ```

# Template for fraud indicators - v10: behavioral only
fraud_indicators_template: |
  ## Behavioral Risk Indicators (No fraud history available)
  - Total Transactions: {total_transactions}
  - Total GMV: ${total_gmv}
  - Average Transaction Value: ${avg_tx_value}
  - Transaction Value Std Dev: ${std_tx_value}
  - Unique Devices: {device_count}
  - Unique IPs: {ip_count}
  - Unique Merchants: {merchant_count}

# Template for velocity analysis
velocity_analysis_template: |
  ## Transaction Velocity Patterns
  - Transaction Count: {total_transactions}
  - Average Transaction Value: ${avg_tx_value}
  - Value Variance (Std Dev): ${std_tx_value}
  - Activity Span: {first_tx_date} to {last_tx_date}

# Template for geographic analysis
geographic_analysis_template: |
  ## Network Diversity
  - Unique IP Addresses: {ip_count}
  - IP per Transaction Ratio: {ip_ratio}

# Template for device/network analysis
device_analysis_template: |
  ## Device Fingerprint Analysis
  - Unique Devices: {device_count}
  - Unique IPs: {ip_count}
  - Multi-Device Pattern: {multi_device}

# Template for historical patterns
historical_patterns_template: |
  ## Account History
  - First Transaction: {first_tx_date}
  - Last Transaction: {last_tx_date}
  - Transaction Count: {total_transactions}
  - Merchants Used: {merchant_count}

# Batch analysis prompt
batch_analysis_prompt: |
  Analyze {entity_count} entities for future fraud risk using statistical anomaly detection.

  For each entity, calculate derived features and only flag CLEAR outliers.
  Remember: 99.3% of entities are legitimate.

  {entities_data}

  Provide JSON array:
  ```json
  [
    {{
      "entity_id": "<entity identifier>",
      "risk_score": <float 0.0-1.0>,
      "confidence": <float 0.0-1.0>,
      "prediction": "<FRAUD|LEGITIMATE>",
      "reasoning": "<brief explanation>",
      "anomaly_count": <int>
    }}
  ]
  ```

# Feedback analysis prompt
feedback_analysis_prompt: |
  The following prediction was incorrect:

  ## Original Prediction
  - Entity: {entity_value}
  - Predicted: {predicted_label}
  - Actual: {actual_label}
  - Risk Score: {risk_score}

  ## Entity Behavioral Data (Feature Period)
  {entity_data}

  ## Actual Outcome (Observation Period)
  - Committed Fraud: {committed_fraud}

  Analyze why this prediction was incorrect:
  ```json
  {{
    "error_type": "<false_positive|false_negative>",
    "likely_cause": "<explanation>",
    "derived_features_at_error": {{
      "device_per_tx": <float>,
      "ip_per_tx": <float>,
      "cv_tx_value": <float>
    }},
    "missed_patterns": [<list of patterns that should have been weighted differently>],
    "suggested_adjustments": {{
      "threshold_adjustment": <suggested threshold change>,
      "weight_adjustments": {{<suggested weight changes>}}
    }}
  }}
  ```
